{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Sampler from Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pseyepy import Camera, Stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./footage_test/\"\n",
    "output_json_path = \"./coordinates_data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to init\n",
      "pyc count: \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# initialize all connected cameras\n",
    "c = Camera(fps=100)\n",
    "\n",
    "buffer = []\n",
    "max_count = 200\n",
    "# read from the camera/s\n",
    "while True:\n",
    "    frames, timestamp = c.read()\n",
    "    if frames and timestamp:\n",
    "        buffer.append(zip(frames,timestamp))\n",
    "    # print(len(buffer))\n",
    "    if len(buffer)>=max_count:break\n",
    "c.end()\n",
    "\n",
    "for buff in buffer:\n",
    "    for i,(frame,ts) in enumerate(buff):\n",
    "    # for i,(frame,ts) in enumerate(zip(frames,timestamp)):\n",
    "        time = datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H:%M:%S.%f')\n",
    "        #print(i, time)\n",
    "        # plt.figure()\n",
    "        # plt.imshow(frame)\n",
    "        #print(f'{save_path}{i}/{time}.png')\n",
    "        cv2.imwrite(f'{save_path}{i}/{time}.png',frame)\n",
    "    # when finished, close the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the video file\n",
    "video_path = \"./footage_video/calibration1_0.avi\"\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Define a kernel for the morphological operation\n",
    "# kernel = np.ones((3, 3), np.uint8)\n",
    "kernel = np.array([[0, 1, 0],[1, 1, 1],[0, 1, 0]], np.uint8)\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    # Read until the video is completed\n",
    "    while cap.isOpened():\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Convert frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply binarization\n",
    "            _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Apply the closing morphological operation\n",
    "            opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Frame', opening)\n",
    "            # cv2.imshow('Frame', binary)\n",
    "\n",
    "            # Press Q on keyboard to exit\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Close all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates data saved to ./coordinates_data_calibration1_0.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Path to the video file\n",
    "video_path = \"./footage_video/calibration1_0.avi\"\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Define a kernel for the morphological operation\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "\n",
    "# Initialize a list to store the coordinates\n",
    "coordinates_data = []\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    frame_number = 0\n",
    "    # Read until the video is completed\n",
    "    while cap.isOpened():\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame_number += 1\n",
    "            # Convert frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply binarization\n",
    "            _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Apply the closing morphological operation\n",
    "            closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Initialize a list to store coordinates for the current frame\n",
    "            frame_coordinates = []\n",
    "\n",
    "            # Convert the frame to RGB\n",
    "            closing = cv2.cvtColor(closing, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            # Loop over the contours to find the center coordinates\n",
    "            for contour in contours:\n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    # Draw the center of the contour on the frame\n",
    "                    cv2.circle(closing, (cX, cY), 1, (0, 255, 0), -1)\n",
    "                    # Append the coordinates to the list\n",
    "                    frame_coordinates.append((cX, cY))\n",
    "\n",
    "            # Append the frame data to the main list\n",
    "            coordinates_data.append({\n",
    "                \"frame\": frame_number,\n",
    "                \"coordinates\": frame_coordinates\n",
    "            })\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Frame', closing)\n",
    "\n",
    "            # Press Q on keyboard to exit\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Close all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "output_json_path = f\"./coordinates_data_{video_path.split('/')[-1][:-4]}.json\"\n",
    "# Save the collected coordinates data to a JSON file\n",
    "with open(output_json_path, 'w') as json_file:\n",
    "    json.dump(coordinates_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Coordinates data saved to {output_json_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
